{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPksb2mb0NpzRmHw+YM6ApZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "xmEL18_-Zk1L"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               in_channels:int=3,\n",
        "               stride:int=16,\n",
        "               kernel:int=16,\n",
        "               embedding_dim:int=768):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                          out_channels=embedding_dim,\n",
        "                          stride=stride,\n",
        "                          kernel_size=kernel,\n",
        "                          padding=0,\n",
        "                          )\n",
        "\n",
        "\n",
        "    self.flatten = nn.Flatten(start_dim=2,end_dim=3)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    return x.permute(0,2,1)"
      ],
      "metadata": {
        "id": "7YJZtzkPZ5nE"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size=16\n",
        "c=3\n",
        "height = 224\n",
        "width = 224\n",
        "print(f\"patch size :{patch_size}, C :{c} , height :{height} , widht :{width}\")\n",
        "embedding_dim = (patch_size**2)*c\n",
        "print(f\"embedding dimension :{embedding_dim}\")\n",
        "\n",
        "patch = PatchEmbedding(in_channels=3,\n",
        "                       stride=16,\n",
        "                       kernel=16,\n",
        "                       embedding_dim=768)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2wvRxHAbYWn",
        "outputId": "7a9aafe6-83a1-4601-9612-da95c07c93a0"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patch size :16, C :3 , height :224 , widht :224\n",
            "embedding dimension :768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadSelfAttentionBlock(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self,\n",
        "               embedding_dim:int=768,\n",
        "               num_heads:int=12,\n",
        "               attn_dropout:float=0.0):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(normalized_shape=embedding_dim)\n",
        "\n",
        "\n",
        "    self.multi_head_attention = nn.MultiheadAttention(embed_dim=embedding_dim,\n",
        "                                                      num_heads=num_heads,\n",
        "                                                      dropout=attn_dropout,\n",
        "                                                      batch_first=True)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.layer_norm(x)\n",
        "    x,_ = self.multi_head_attention(query=x,\n",
        "                                  key=x,\n",
        "                                  value=x,\n",
        "                                  need_weights=False)\n",
        "    return x\n",
        "    print(type(x))\n",
        "\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "RICNS_dqa51k"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPBlock(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self,\n",
        "               embedding_dim:int=768,\n",
        "               mlp_dim:int=3072,\n",
        "               dropout:float=0.1\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_norm = nn.LayerNorm(normalized_shape = embedding_dim)\n",
        "\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(in_features=embedding_dim,\n",
        "                  out_features=mlp_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.Linear(in_features=mlp_dim,\n",
        "                  out_features=embedding_dim),\n",
        "        nn.Dropout(p=dropout)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.layer_norm(x)\n",
        "\n",
        "\n",
        "    x = self.mlp(x)\n",
        "\n",
        "\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "nAPEabq5gDqX"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchinfo\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "Tfxu9E_4sB3-"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self,\n",
        "               embedding_dim:int=768,\n",
        "               num_heads:int=12,\n",
        "               mlp_heads:int=3072,\n",
        "               attn_dropout:float=0.0,\n",
        "               dropout:float=0.1\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.msa_block = MultiheadSelfAttentionBlock(embedding_dim=embedding_dim,\n",
        "                            num_heads=num_heads,\n",
        "                            attn_dropout=attn_dropout)\n",
        "    self.mlp_block = MLPBlock(embedding_dim=embedding_dim,\n",
        "                            mlp_dim=mlp_heads,\n",
        "                            dropout=dropout)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.msa_block(x)\n",
        "    x = self.mlp_block(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "24Y8saHpFhKd"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               N:int=196,\n",
        "               embedding_dim:int=768,\n",
        "               num_heads:int=12,\n",
        "               mlp_heads:int=3072,\n",
        "               attn_dropout:float=0.0,\n",
        "               dropout:float=0.1,\n",
        "               patch_size=16):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    # self.embedding_dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "\n",
        "    self.patch_embedding = PatchEmbedding(in_channels=3,\n",
        "                                          embedding_dim=embedding_dim,\n",
        "                                          stride = patch_size,\n",
        "                                          kernel=patch_size)\n",
        "\n",
        "\n",
        "    self.class_token = nn.Parameter(torch.randn((batch_size,\n",
        "                                                 1,\n",
        "                                                 embedding_dim),requires_grad=True))\n",
        "\n",
        "\n",
        "    self.position_embedding = nn.Parameter(torch.randn(1,\n",
        "                                                       N+1,\n",
        "                                                       embedding_dim),requires_grad=True)\n",
        "\n",
        "\n",
        "    self.embedding_dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "\n",
        "    self.transformer_encoder = nn.Sequential(\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                TransformerEncoderBlock(embedding_dim=embedding_dim,\n",
        "                                                        num_heads=num_heads,\n",
        "                                                        mlp_heads=mlp_heads,\n",
        "                                                        attn_dropout=attn_dropout,\n",
        "                                                        dropout=dropout),\n",
        "                                )\n",
        "\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "                                    nn.LayerNorm(normalized_shape = embedding_dim),\n",
        "                                    nn.Linear(in_features=embedding_dim,\n",
        "                                    out_features=1000),\n",
        "                                    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    # x = self.dropout(x)\n",
        "    x = self.patch_embedding(x)\n",
        "\n",
        "    cls = self.class_token.expand(x.shape[0],-1,-1)\n",
        "\n",
        "    x = torch.cat((cls,x),dim=1)\n",
        "\n",
        "\n",
        "    x = x + self.position_embedding\n",
        "\n",
        "    # x = self.layer_norm(x)\n",
        "    x = self.embedding_dropout(x)\n",
        "\n",
        "\n",
        "    msa = self.multi_head_attention(x)\n",
        "\n",
        "    msa = msa + x\n",
        "    msa = self.layer_norm(msa)\n",
        "    mlp = self.mlp(msa)\n",
        "\n",
        "    mlp = mlp+msa\n",
        "    mlp = self.classifier(mlp)\n",
        "    return mlp"
      ],
      "metadata": {
        "id": "4M-eIo-vujVP"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = ViT(N=196,\n",
        "              embedding_dim=embedding_dim,\n",
        "              num_heads=12,\n",
        "              mlp_heads=3072,\n",
        "              attn_dropout=0.0,\n",
        "              dropout=0.1,\n",
        "              patch_size=16)"
      ],
      "metadata": {
        "id": "KfFc8v_t3IcQ"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=t,\n",
        "        # input_size=(1, 3, 224, 224), # (batch_size, color_channels, height, width)\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[ \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqIaEfYeude_",
        "outputId": "d322e798-a301-493e-8a8a-62845cfb83b0"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==============================================================================================================\n",
              "Layer (type (var_name))                                                Param #              Trainable\n",
              "==============================================================================================================\n",
              "ViT (ViT)                                                              152,064              True\n",
              "├─PatchEmbedding (patch_embedding)                                     --                   True\n",
              "│    └─Conv2d (conv)                                                   590,592              True\n",
              "│    └─Flatten (flatten)                                               --                   --\n",
              "├─Dropout (embedding_dropout)                                          --                   --\n",
              "├─Sequential (transformer_encoder)                                     --                   True\n",
              "│    └─TransformerEncoderBlock (0)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (1)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (2)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (3)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (4)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (5)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (6)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (7)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (8)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (9)                                     --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (10)                                    --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "│    └─TransformerEncoderBlock (11)                                    --                   True\n",
              "│    │    └─MultiheadSelfAttentionBlock (msa_block)                    2,363,904            True\n",
              "│    │    └─MLPBlock (mlp_block)                                       4,723,968            True\n",
              "├─Sequential (classifier)                                              --                   True\n",
              "│    └─LayerNorm (0)                                                   1,536                True\n",
              "│    └─Linear (1)                                                      769,000              True\n",
              "==============================================================================================================\n",
              "Total params: 86,567,656\n",
              "Trainable params: 86,567,656\n",
              "Non-trainable params: 0\n",
              "=============================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser = torch.optim.Adam(params = t.parameters(),\n",
        "                             lr=3e-3,\n",
        "                             betas=(0.9,0.999),\n",
        "                             weight_decay=0.3)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "C8DXuHvYKT0h"
      },
      "execution_count": 251,
      "outputs": []
    }
  ]
}